{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import gensim\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Event ID', 'Title', 'Abstract', 'Is_Food', 'ab_clean', 'ab_clean_ph',\n",
       "       'zero_length', 'hashtags', 'in_reply_to_status_text', 'mentions',\n",
       "       'tweet_found'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_Data = pd.read_csv(\"train_with_scraping_1.csv\")\n",
    "all_Data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_Data.loc[all_Data[\"Abstract\"].isnull(), 'Abstract'] = all_Data[all_Data[\"Abstract\"].isnull()]['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_Data.loc[all_Data['in_reply_to_status_text'].notnull(), 'Abstract'] = all_Data[all_Data['in_reply_to_status_text'].notnull()]['in_reply_to_status_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2958"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试食品相关数据\n",
    "all_Data = all_Data[all_Data['Event ID'] > 0]\n",
    "len(all_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_command = all_Data.Abstract.map(lambda x: x.lstrip().rstrip())\n",
    "handle_all_command = []\n",
    "lines = all_command.tolist()\n",
    "stopwords = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "table = str.maketrans(\"\",\"\",string.punctuation)\n",
    "for line in lines:\n",
    "    line = \" \".join([word for word in line.split(\" \") if '@' not in word and 'http' not in word and \"RT\" not in word])\n",
    "    tokens = nltk.word_tokenize(line)\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    tokens = [w for w in tokens if w.isalpha()]\n",
    "    tokens = [w for w in tokens if w not in stopwords and w ]\n",
    "    handle_all_command.append(tokens)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 3, 3, 3, 3, 3, 3, 3, 3]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [len(x) for x in handle_all_command]\n",
    "sorted(l)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "\n",
    "dic = Dictionary(handle_all_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dic.doc2bow(text) for text in handle_all_command]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.109*\"nut\" + 0.101*\"butters\" + 0.095*\"listeria\" + 0.087*\"recalls\" + 0.081*\"nationwide\" + 0.061*\"oskri\" + 0.051*\"market\" + 0.042*\"thrive\" + 0.034*\"recall\" + 0.034*\"due\"'),\n",
       " (1,\n",
       "  '0.149*\"food\" + 0.116*\"recall\" + 0.096*\"dog\" + 0.049*\"hill\" + 0.043*\"pet\" + 0.042*\"vitamin\" + 0.030*\"levels\" + 0.028*\"nutrition\" + 0.025*\"canned\" + 0.021*\"smartnews\"'),\n",
       " (2,\n",
       "  '0.099*\"general\" + 0.099*\"mills\" + 0.096*\"flour\" + 0.087*\"salmonella\" + 0.055*\"gold\" + 0.055*\"medal\" + 0.051*\"bags\" + 0.049*\"recalls\" + 0.033*\"fears\" + 0.031*\"unbleached\"'),\n",
       " (3,\n",
       "  '0.098*\"butter\" + 0.064*\"found\" + 0.060*\"peanut\" + 0.046*\"cause\" + 0.038*\"aflatoxin\" + 0.025*\"products\" + 0.021*\"reports\" + 0.021*\"serious\" + 0.020*\"consumer\" + 0.019*\"government\"'),\n",
       " (4,\n",
       "  '0.054*\"de\" + 0.035*\"en\" + 0.028*\"insider\" + 0.026*\"la\" + 0.025*\"organic\" + 0.017*\"duraznos\" + 0.016*\"por\" + 0.016*\"nt\" + 0.016*\"produce\" + 0.016*\"cereal\"'),\n",
       " (5,\n",
       "  '0.100*\"perdue\" + 0.094*\"recall\" + 0.068*\"health\" + 0.039*\"please\" + 0.032*\"across\" + 0.030*\"food\" + 0.029*\"another\" + 0.029*\"feta\" + 0.028*\"read\" + 0.022*\"share\"'),\n",
       " (6,\n",
       "  '0.145*\"peaches\" + 0.144*\"nectarines\" + 0.133*\"plums\" + 0.120*\"listeria\" + 0.087*\"recalled\" + 0.051*\"stores\" + 0.044*\"recall\" + 0.043*\"fresh\" + 0.032*\"concerns\" + 0.027*\"fda\"'),\n",
       " (7,\n",
       "  '0.076*\"recall\" + 0.054*\"flour\" + 0.050*\"mills\" + 0.049*\"general\" + 0.037*\"unbleached\" + 0.036*\"gold\" + 0.036*\"medal\" + 0.030*\"bags\" + 0.029*\"announced\" + 0.029*\"voluntary\"'),\n",
       " (8,\n",
       "  '0.069*\"recall\" + 0.046*\"california\" + 0.044*\"food\" + 0.041*\"owners\" + 0.033*\"pet\" + 0.030*\"hills\" + 0.029*\"dog\" + 0.023*\"washington\" + 0.019*\"pieces\" + 0.019*\"like\"'),\n",
       " (9,\n",
       "  '0.126*\"sold\" + 0.120*\"walmart\" + 0.110*\"aldi\" + 0.106*\"costco\" + 0.103*\"fruit\" + 0.080*\"listeria\" + 0.078*\"due\" + 0.072*\"recalled\" + 0.036*\"recall\" + 0.022*\"contain\"'),\n",
       " (10,\n",
       "  '0.126*\"via\" + 0.084*\"nuggets\" + 0.083*\"chicken\" + 0.045*\"recalled\" + 0.044*\"undeclared\" + 0.041*\"news\" + 0.034*\"due\" + 0.032*\"breast\" + 0.025*\"milk\" + 0.025*\"fox\"'),\n",
       " (11,\n",
       "  '0.180*\"possible\" + 0.152*\"contamination\" + 0.097*\"recalled\" + 0.090*\"listeria\" + 0.081*\"sold\" + 0.080*\"nectarines\" + 0.075*\"peaches\" + 0.062*\"walmart\" + 0.024*\"states\" + 0.011*\"containing\"'),\n",
       " (12,\n",
       "  '0.045*\"salmonella\" + 0.042*\"product\" + 0.039*\"bags\" + 0.037*\"mills\" + 0.036*\"general\" + 0.035*\"flour\" + 0.033*\"date\" + 0.029*\"april\" + 0.028*\"used\" + 0.028*\"better\"'),\n",
       " (13,\n",
       "  '0.039*\"new\" + 0.035*\"food\" + 0.022*\"monocytogenes\" + 0.021*\"warning\" + 0.020*\"drug\" + 0.019*\"administration\" + 0.019*\"may\" + 0.018*\"di\" + 0.018*\"york\" + 0.017*\"contaminated\"'),\n",
       " (14,\n",
       "  '0.088*\"nuggets\" + 0.087*\"chicken\" + 0.071*\"tyson\" + 0.053*\"pounds\" + 0.052*\"foods\" + 0.044*\"rubber\" + 0.037*\"recalls\" + 0.026*\"recall\" + 0.025*\"us\" + 0.024*\"recalling\"'),\n",
       " (15,\n",
       "  '0.118*\"several\" + 0.080*\"spinach\" + 0.078*\"foods\" + 0.073*\"salmonella\" + 0.061*\"baby\" + 0.057*\"whole\" + 0.042*\"products\" + 0.041*\"alert\" + 0.037*\"recalls\" + 0.030*\"recall\"')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LdaModel(corpus=corpus, id2word=dic, num_topics=16, passes=100) \n",
    "lda.print_topics(num_topics=16, num_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[81, 199, 1035, 21, 23, 24, 449, 297, 30, 154, 49, 149, 145, 71, 111, 120]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = [0 for i in range(16)]\n",
    "for item in lda[corpus]:\n",
    "    resTopic, maxProp = 0, 0\n",
    "    for tup in item:\n",
    "        if tup[1] > maxProp:\n",
    "            maxProp = tup[1]\n",
    "            resTopic = tup[0]\n",
    "    counter[resTopic] += 1\n",
    "counter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
